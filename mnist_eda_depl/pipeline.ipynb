{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "import kfp.dsl as dsl\n",
    "from typing import NamedTuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Download Data func ###########\n",
    "def download_data(bucket: str, training_data_path: str, output_data_path: OutputPath('CSV')):\n",
    "    import boto3\n",
    "    s3 = boto3.client(\"s3\", region_name='ap-south-1')\n",
    "    s3.download_file(bucket, training_data_path, output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make a component of download_data function ################\n",
    "download_data_op = comp.func_to_container_op(download_data,\n",
    "                                             base_image='python:3.7-slim',\n",
    "                                             output_component_file='components/download_data.yaml',\n",
    "                                             packages_to_install=['boto3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Normalize Data func ################################\n",
    "def split_data(\n",
    "    input_data_path: InputPath(\"CSV\"), \n",
    "    output_training_data: OutputPath(\"CSV\"), \n",
    "    output_training_labels: OutputPath(\"CSV\"), \n",
    "    output_test_data: OutputPath(\"CSV\"), \n",
    "    output_test_labels: OutputPath(\"CSV\")\n",
    "):\n",
    "    import pandas as pd\n",
    "    df_train = df = pd.read_csv(input_data_path, sep=',', header=0)\n",
    "    \n",
    "    x = df_train.iloc[:, 1:]\n",
    "    y = df_train['label'].tolist()\n",
    "\n",
    "    # # Select 10000 rows data as a testing dataset\n",
    "    x_test = x.iloc[0:10000, :].values.astype('float32') # all pixel values \n",
    "    y_test = y[0:10000] # Select label for testing data\n",
    "    x_train = x.iloc[10000:, :].values.astype('float32') # all pixel values \n",
    "    y_train = y[10000:]\n",
    "    \n",
    "    pd.DataFrame(x_train).to_csv(output_training_data, index=False)\n",
    "    pd.DataFrame(y_train).to_csv(output_training_labels, index=False)\n",
    "    \n",
    "    pd.DataFrame(x_test).to_csv(output_test_data, index=False)\n",
    "    pd.DataFrame(y_test).to_csv(output_test_labels, index=False)\n",
    "    print(\"ALL DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_op = comp.func_to_container_op(split_data, \n",
    "                                      base_image='python:3.7-slim',\n",
    "                                      output_component_file='components/split_data.yaml',\n",
    "                                      packages_to_install=['pandas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(\n",
    "    training_data_path: InputPath('CSV'), \n",
    "    test_data_path: InputPath('CSV'), \n",
    "    normalized_training_data: OutputPath('CSV'), \n",
    "    normalized_test_data: OutputPath('CSV')\n",
    "):\n",
    "    import pandas as pd\n",
    "    \n",
    "    x_train = pd.read_csv(training_data_path)\n",
    "    x_test = pd.read_csv(test_data_path)\n",
    "    \n",
    "    x_train = x_train/255.0\n",
    "    x_test = x_test/255.0\n",
    "    \n",
    "    x_train.to_csv(normalized_training_data, index=False)\n",
    "    x_test.to_csv(normalized_test_data, index=False)\n",
    "    \n",
    "    print(\"ALL DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_data_op = comp.func_to_container_op(normalize_data,\n",
    "                                          base_image='python:3.7-slim',\n",
    "                                          output_component_file='components/normalize_data',\n",
    "                                          packages_to_install=['pandas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    n_estimators: int, \n",
    "    depth: int, \n",
    "    random_state: int, \n",
    "    mlflow_tracking_uri: str,\n",
    "    mlflow_experiment_name: str,\n",
    "    model_name: str,\n",
    "    training_data_path: InputPath('CSV'), \n",
    "    training_labels_path: InputPath('CSV'), \n",
    "    test_data_path: InputPath('CSV'),\n",
    "    test_labels_path: InputPath('CSV')\n",
    "    ):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    x_train = pd.read_csv(training_data_path)\n",
    "    y_train = pd.read_csv(training_labels_path)['0'].tolist()\n",
    "    \n",
    "    \n",
    "    x_test = pd.read_csv(test_data_path)\n",
    "    y_test = pd.read_csv(test_labels_path)['0'].tolist()\n",
    "    \n",
    "    print(x_train, y_train, x_test, y_test)\n",
    "    model_clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth, random_state=random_state)\n",
    "\n",
    "    # Train the Random Forest algorithm\n",
    "    model_clf.fit(x_train, y_train)\n",
    "    \n",
    "    # validate\n",
    "    y_pred = model_clf.predict(x_test)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    total = len(y_pred)\n",
    "    wrong = 0\n",
    "    for pred, truth in zip(y_pred, y_test):\n",
    "        wrong += 1 if pred != truth else 0\n",
    "\n",
    "    accuracy = ((total - wrong)/total) * 100.0\n",
    "\n",
    "    ########## log model ####################\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", depth)\n",
    "        mlflow.log_param(\"random_state\", random_state)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        mlflow.sklearn.log_model(model_clf, \"model\", registered_model_name=model_name)\n",
    "\n",
    "        model_artifact_location = run.info.artifact_uri + \"/model\"\n",
    "        logged_model = 'runs:/'+run.info.run_id+'/model'\n",
    "\n",
    "    return { 'accuracy': accuracy, 'model_path': logged_model }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = comp.func_to_container_op(train,\n",
    "                                          base_image='python:3.7',\n",
    "                                          output_component_file='components/train',\n",
    "                                          packages_to_install=['mlflow', 'pandas', 'sklearn', 'boto3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Define Pipeline ######################\n",
    "@dsl.pipeline(\n",
    "    name='MNIST Random Forest Pipeline - 2',\n",
    "    description='Training pipeline for time series forecasting on household power consumption dataset.'\n",
    "\n",
    ")\n",
    "def training_pipeline(bucket, path):\n",
    "    # Returns a dsl.ContainerOp class instance.\n",
    "    download_data_task = download_data_op(\n",
    "        bucket, path).set_display_name('Download Raw Data')\n",
    "    \n",
    "    key_output = str(list(download_data_task.outputs.keys())[0])\n",
    "\n",
    "    split_data_task = split_data_op(download_data_task.outputs[key_output]).after(\n",
    "        download_data_task).set_display_name('Split Data')\n",
    "\n",
    "    training_data_path = split_data_task.outputs['output_training_data']\n",
    "    test_data_path = split_data_task.outputs['output_test_data']\n",
    "    training_labels_path = split_data_task.outputs['output_training_labels']\n",
    "    test_labels_path = split_data_task.outputs['output_test_labels']\n",
    "    \n",
    "    normalize_data_task = normalize_data_op(training_data_path, test_data_path).after(split_data_task).set_display_name('Normalize Data')\n",
    "    \n",
    "    normalized_training_data_path = normalize_data_task.outputs['normalized_training_data']\n",
    "    normalized_test_data_path = normalize_data_task.outputs['normalized_test_data']\n",
    "    \n",
    "    mlflow_tracking_uri = \"http://mlflow-service.kubeflow.svc.cluster.local:80\"\n",
    "    mlflow_experiment_name = \"mnist-rf\"\n",
    "    model_name = \"MNIST-RF\"\n",
    "    \n",
    "    ################################################################\n",
    "    params = [(100, 1, 0), (500, 4, 3), (800, 3, 0), (50, 4, 0)]\n",
    "    \n",
    "    task_num = 0\n",
    "    \n",
    "    train_output = {}\n",
    "    for model_num, (n_estimators, depth, random_state) in enumerate(params):\n",
    "        task_num += 1\n",
    "        train_model_task = train_op(\n",
    "            n_estimators, \n",
    "            depth, \n",
    "            random_state, \n",
    "            mlflow_tracking_uri, \n",
    "            mlflow_experiment_name, \n",
    "            model_name, \n",
    "            normalized_training_data_path,\n",
    "            training_labels_path,\n",
    "            normalized_test_data_path,\n",
    "            test_labels_path\n",
    "        ).after(normalize_data_task).set_display_name('Model Training: '+str(model_num)).set_memory_request('1G').set_cpu_request('0.5')\n",
    "        \n",
    "        train_output['Model Training: '+str(model_num)] = train_model_task.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### COMPILE AND TEST PIPELINE DEFINITION (OPTIONAL) ########################\n",
    "import kfp\n",
    "kfp.compiler.Compiler().compile(training_pipeline, 'workflow.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://af498242-istiosystem-istio-2af2-1562593475.ap-south-1.elb.amazonaws.com/pipeline/#/experiments/details/19ea830e-fe8f-4297-b3df-4ef7034ecd9d\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://af498242-istiosystem-istio-2af2-1562593475.ap-south-1.elb.amazonaws.com/pipeline/#/runs/details/917885a2-259e-49fb-a7bc-ad0ae9e34a9c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=917885a2-259e-49fb-a7bc-ad0ae9e34a9c)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################### Run Pipeline ############################################\n",
    "arguments = {\"bucket\": \"kubeflow-ds-test-raw-lake\", \"path\": \"data/train.csv\"}\n",
    "\n",
    "authservice_session='authservice_session=MTYzNzcyODcwNnxOd3dBTkVKSVJWTmFWVXBLUmxWUE5FWTNRbFpDUlVKVVVsTktWa05KTlZWSldGQlNRa2hSTWs5T1UwTXlUMEZRU0U1WFZGRTJOVUU9fC6CMExKrebI0JWAtEldZYXftE7SRLX4E7wKdIeWbh_3'\n",
    "client = kfp.Client(host='http://af498242-istiosystem-istio-2af2-1562593475.ap-south-1.elb.amazonaws.com/pipeline', cookies=authservice_session)\n",
    "namespace='nikunj-sharma'\n",
    "\n",
    "# Submit a pipeline run\n",
    "client.create_run_from_pipeline_func(\n",
    "    training_pipeline, arguments=arguments, namespace=namespace, experiment_name='MNIST-RF-EXP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Pipeline link <a href=http://af498242-istiosystem-istio-2af2-1562593475.ap-south-1.elb.amazonaws.com/pipeline/#/pipelines/details/27f0ead0-adc4-4250-9efd-86c112ed595f>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2021, 11, 24, 6, 56, 34, tzinfo=tzlocal()),\n",
       " 'default_version': {'code_source_url': None,\n",
       "                     'created_at': datetime.datetime(2021, 11, 24, 6, 56, 34, tzinfo=tzlocal()),\n",
       "                     'id': '27f0ead0-adc4-4250-9efd-86c112ed595f',\n",
       "                     'name': 'MNIST RF Pipeline',\n",
       "                     'package_url': None,\n",
       "                     'parameters': [{'name': 'bucket', 'value': None},\n",
       "                                    {'name': 'path', 'value': None}],\n",
       "                     'resource_references': [{'key': {'id': '27f0ead0-adc4-4250-9efd-86c112ed595f',\n",
       "                                                      'type': 'PIPELINE'},\n",
       "                                              'name': None,\n",
       "                                              'relationship': 'OWNER'}]},\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'id': '27f0ead0-adc4-4250-9efd-86c112ed595f',\n",
       " 'name': 'MNIST RF Pipeline',\n",
       " 'parameters': [{'name': 'bucket', 'value': None},\n",
       "                {'name': 'path', 'value': None}],\n",
       " 'url': None}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## SAVE PIPELINE On KUBEFLOW ###############################################\n",
    "client.upload_pipeline(pipeline_package_path='workflow.yaml',\n",
    "                             pipeline_name='MNIST RF Pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
